{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LVnT9VkZKoX"
   },
   "source": [
    "# HapTree-X experimental workbook\n",
    "\n",
    "## Tools\n",
    "\n",
    "The following tools were used for experiment preparation:\n",
    "\n",
    "| Tool | Version |\n",
    "|------|-----|\n",
    "| HapTree-X | [b87ea39fa8](https://github.com/LillianZ/HapTreeX/tree/b87ea39fa8024d966ebe5ad027918c65053b6db2) |\n",
    "| STAR | [2.6.1d](https://github.com/alexdobin/STAR/archive/2.6.1d.tar.gz) |\n",
    "| HapCUT2 | [782e537](https://github.com/vibansal/HapCUT2/tree/782e537a66b0372983e873573ed7616511825a77) |\n",
    "| HapCUT | [0.7 (254c473)](https://github.com/vibansal/hapcut/tree/254c473066565e6b9d11b0e725e17ff910dcfbb1) |\n",
    "| GATK | [3.8-1-0 (gf15c1c3ef)](https://software.broadinstitute.org/gatk/download/auth?package=GATK-archive&version=3.8-1-0-gf15c1c3ef) |\n",
    "| phASER | [1.1.0 (b7c28f4)](https://github.com/secastel/phaser/tree/b7c28f4e37790e7df4f41cf6bf74f9d5f41f7d0c) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File hierarchy\n",
    "\n",
    "- `deniz_old`: whatever Deniz did previously\n",
    "- `resources`: Reference genome (GRCh37), genome annotations and STAR reference genome\n",
    "- `tools`: location of the tools used in these experiments\n",
    "- `samples/SAMPLE`: sample data\n",
    "  - `giab`: Genome in the Bottle data\n",
    "    - `SAMPLE.vcf`: original GIAB VCF\n",
    "      - `SAMPLE.filter.vcf`: GIAB VCF with only heterozygous diploid SNPs\n",
    "      - `SAMPLE.blind.vcf`: Filtered GIAB VCF with any extra information (including phasing!) stripped out\n",
    "    - `SAMPLE.hs37d5.wgs.bam`: Whole genome BAM file from GIAB FTP repository\n",
    "    - `SAMPLE.grch73.wxs.bam`: Exome BAM file from GIAB FTP repository\n",
    "  - `rna`: RNA-seq data (backed up on `/data/cb/`)\n",
    "    - `fastq`: Original RNA-seq FASTQs from Sarah\n",
    "    - `SAMPLE.star.sam`: STAR-produced SAM\n",
    "    - `SAMPLE.name-clean.sam`: filtered and name-sorted STAR SAM\n",
    "    - `SAMPLE.name-clean.bam`: filtered and position-sorted STAR BAM\n",
    "  - `phaser`: phASER output on `SAMPLE.name-clean.bam`\n",
    "    - `SAMPLE.<xxx>`: various phASER files\n",
    "  - `hapcut`: HapCUT-related files\n",
    "    - `SAMPLE-rna.chair`: HAIRS from RNA-seq BAM \n",
    "    - `SAMPLE-wxs.chair`: HAIRS from Exome GIAB BAM \n",
    "    - `SAMPLE-wgs.chair`: HAIRS from WGS GIAB BAM \n",
    "  - `haptreex`: HapTree-X-related files\n",
    "    - `SAMPLE-rna.chair`: Chair output from RNA-seq BAM \n",
    "    - `rna`: HapTree-X output with `--RNAfragmat SAMPLE-rna.chair`  \n",
    "- `tmp`: triaging directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "### GIAB data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zLyZap1A1UZO"
   },
   "source": [
    "To download GIAB data run:\n",
    "\n",
    "```bash\n",
    "# Do the following 2 steps for each ${sample} :\n",
    "cd samples/${sample}\n",
    "mkdir -p giab\n",
    "\n",
    "# Get WGS BAMs\n",
    "wget -c -O giab/NA12878.hs37d5.wgs.bam \\\n",
    "  ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NIST_NA12878_HG001_HiSeq_300x/NHGRI_Illumina300X_novoalign_bams/HG001.hs37d5.300x.bam\n",
    "wget -c -O giab/NA24385.hs37d5.wgs.bam \\\n",
    "  ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/NIST_HiSeq_HG002_Homogeneity-10953946/NHGRI_Illumina300X_AJtrio_novoalign_bams/HG002.hs37d5.300x.bam\n",
    "wget -c -O giab/NA24149.hs37d5.wgs.bam \\\n",
    "  ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG003_NA24149_father/NIST_HiSeq_HG003_Homogeneity-12389378/NHGRI_Illumina300X_AJtrio_novoalign_bams/HG003.hs37d5.300x.bam \n",
    "wget -c -O giab/NA24143.hs37d5.wgs.bam \\\n",
    "  ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG004_NA24143_mother/NIST_HiSeq_HG004_Homogeneity-14572558/NHGRI_Illumina300X_AJtrio_novoalign_bams/HG004.hs37d5.300x.bam\n",
    "wget -c -O giab/NA24631.hs37d5.wgs.bam \\\n",
    "  ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/HG005_NA24631_son_HiSeq_300x/NHGRI_Illumina300X_Chinesetrio_novoalign_bams/HG005.hs37d5.300x.bam\n",
    "\n",
    "parallel 'samtools index {}' ::: *.bam\n",
    "\n",
    "# Get WXS BAMs\n",
    "wget -c -O giab/NA24631.hg19.wxs.NIST7035-1.bam \\\n",
    "  https://ftp-trace.ncbi.nih.gov/giab/ftp/data/NA12878/Garvan_NA12878_HG001_HiSeq_Exome/project.NIST_NIST7035_H7AP8ADXX_TAAGGCGA_1_NA12878.bwa.markDuplicates.bam\n",
    "wget -c -O giab/NA24631.hg19.wxs.NIST7035-2.bam \\\n",
    "  https://ftp-trace.ncbi.nih.gov/giab/ftp/data/NA12878/Garvan_NA12878_HG001_HiSeq_Exome/project.NIST_NIST7035_H7AP8ADXX_TAAGGCGA_2_NA12878.bwa.markDuplicates.bam\n",
    "wget -c -O giab/NA24631.hg19.wxs.NIST7086-1.bam \\\n",
    "  https://ftp-trace.ncbi.nih.gov/giab/ftp/data/NA12878/Garvan_NA12878_HG001_HiSeq_Exome/project.NIST_NIST7086_H7AP8ADXX_CGTACTAG_1_NA12878.bwa.markDuplicates.bam\n",
    "wget -c -O giab/NA24631.hg19.wxs.NIST7086-2.bam \\\n",
    "  https://ftp-trace.ncbi.nih.gov/giab/ftp/data/NA12878/Garvan_NA12878_HG001_HiSeq_Exome/project.NIST_NIST7086_H7AP8ADXX_CGTACTAG_2_NA12878.bwa.markDuplicates.bam\n",
    "\n",
    "wget -c -O giab/NA24385.grch37.wxs.bam \\\n",
    "    ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/OsloUniversityHospital_Exome/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam\t\n",
    "wget -c -O giab/NA24149.grch37.wxs.bam \\\n",
    "  ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG003_NA24149_father/OsloUniversityHospital_Exome/151002_7001448_0359_AC7F6GANXX_Sample_HG003-EEogPU_v02-KIT-Av5_TCTTCACA_L008.posiSrt.markDup.bam\t\n",
    "wget -c -O giab/NA24143.grch37.wxs.bam \\\n",
    "  ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG004_NA24143_mother/OsloUniversityHospital_Exome/151002_7001448_0359_AC7F6GANXX_Sample_HG004-EEogPU_v02-KIT-Av5_CCGAAGTA_L008.posiSrt.markDup.bam\t\n",
    "wget -c -O giab/NA24631.grch37.wxs.bam \\\n",
    "  ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/OsloUniversityHospital_Exome/151002_7001448_0359_AC7F6GANXX_Sample_HG005-EEogPU_v02-KIT-Av5_CGCATACA_L008.posiSrt.markDup.bam\n",
    "\n",
    "# Get VCFs\n",
    "wget -c -O giab/NA12878.vcf.gz \\\n",
    "  https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh37/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.gz\n",
    "wget -c -O giab/NA24385.vcf.gz \\\n",
    "  https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/AshkenazimTrio/HG002_NA24385_son/latest/GRCh37/HG002_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-22_v.3.3.2_highconf_triophased.vcf.gz\n",
    "wget -c -O giab/NA24149.vcf.gz \\\n",
    "  https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/AshkenazimTrio/HG003_NA24149_father/latest/GRCh37/HG003_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X_CHROM1-22_v.3.3.2_highconf.vcf.gz\n",
    "wget -c -O giab/NA24143.vcf.gz \\\n",
    "  https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/AshkenazimTrio/HG004_NA24143_mother/latest/GRCh37/HG004_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X_CHROM1-22_v.3.3.2_highconf.vcf.gz\n",
    "wget -c -O giab/NA24631.vcf.gz \\\n",
    "  https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/ChineseTrio/HG005_NA24631_son/latest/GRCh37/HG005_GRCh37_highconf_CG-IllFB-IllGATKHC-Ion-SOLID_CHROM1-22_v.3.3.2_highconf.vcf.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing GIAB BAMs and VCFs for phasing\n",
    "\n",
    "To clean-up GIAB data and prepare it for phasing run:\n",
    "\n",
    "```bash\n",
    "for sample in NA12878 NA24143 NA24149 NA24385 NA24631 ;\n",
    "do\n",
    "  echo -e \"\\n${sample}\"\n",
    "  echo \"=====================================================\"\n",
    "\n",
    "  # Filter out anything that is not heterozygous biallelic SNP\n",
    "  bcftools view samples/${sample}/giab/${sample}.vcf.gz \\\n",
    "    -g 'het' -m2 -M2 -v snps \\\n",
    "    -o samples/${sample}/giab/${sample}.filter.vcf\n",
    "    \n",
    "  # Remove phasing and other annotations from VCF to \"blind\" it\n",
    "  bcftools annotate -x 'INFO,FMT' samples/${sample}/giab/${sample}.filter.vcf | \\\n",
    "    awk '{if (substr($0,0,1)!=\"#\") { $10=\"0/1\"; } print}' OFS=\"\\t\" \\\n",
    "    > samples/${sample}/giab/${sample}.blind.vcf\n",
    "    \n",
    "  # Create indices\n",
    "  bgzip -c samples/${sample}/giab/${sample}.filter.vcf \\\n",
    "    > samples/${sample}/giab/${sample}.filter.vcf.gz\n",
    "  bgzip -c samples/${sample}/giab/${sample}.blind.vcf \\\n",
    "    > samples/${sample}/giab/${sample}.blind.vcf.gz\n",
    "  parallel --bar tabix -p vcf {} ::: samples/${sample}/giab/*.vcf.gz\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAR RNA-seq alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference preparation\n",
    "\n",
    "To prepare STAR-compatible Human reference run:\n",
    "\n",
    "```bash\n",
    "mkdir -p resources \n",
    "\n",
    "wget -c -P resources \\\n",
    "  ftp://ftp.ensembl.org/pub/grch37/release-94/fasta/homo_sapiens/dna/Homo_sapiens.GRCh37.dna.primary_assembly.fa.gz\n",
    "wget -c -P resources \\ \n",
    "  ftp://ftp.ensembl.org/pub/grch37/release-94/gtf/homo_sapiens/Homo_sapiens.GRCh37.87.gtf.gz\n",
    "\n",
    "gunzip resources/Homo_sapiens.GRCh37.87.gtf.gz\n",
    "gunzip resources/Homo_sapiens.GRCh37.dna.primary_assembly.fa.gz\n",
    "samtools faidx resources/Homo_sapiens.GRCh37.dna.primary_assembly.fa\n",
    "\n",
    "# Reference generation (takes around 1/2 hr)\n",
    "tools/star-v2.6.1d/bin/Linux_x86_64/STAR \\\n",
    "  --runMode genomeGenerate \\\n",
    "  --runThreadN 10 \\\n",
    "  --genomeDir resources/Homo_sapiens.GRCh37 \\\n",
    "  --genomeFastaFiles resources/Homo_sapiens.GRCh37.dna.primary_assembly.fa  \\\n",
    "  --sjdbGTFfile resources/Homo_sapiens.GRCh37.87.gtf \\\n",
    "  --sjdbOverhang 74\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-eNZcJf-fSKh"
   },
   "source": [
    "#### Sample alignment\n",
    "\n",
    "To align each RNA-seq sample run:\n",
    "\n",
    "```bash\n",
    "for sample in NA12878 NA24143 NA24149 NA24385 NA24631 ;\n",
    "do\n",
    "  r1=\"$(ls samples/NA12878/rna/fastq/*R1*.gz | tr '\\n' ',')\"\n",
    "  r2=\"$(ls samples/NA12878/rna/fastq/*R2*.gz | tr '\\n' ',')\"\n",
    "\n",
    "  # Alignment: should take ~10 min and use ~40G of RAM\n",
    "  mesa tools/star-v2.6.1d/bin/Linux_x86_64/STAR \\\n",
    "    --runThreadN 24 \\\n",
    "    --twopassMode Basic \\\n",
    "    --genomeDir resources/Homo_sapiens.GRCh37 \\\n",
    "    --readFilesCommand gunzip -c \\\n",
    "    --outFileNamePrefix \"samples/${sample}/rna/star/${sample}_\" \\\n",
    "    --readFilesIn \"${r1}\" \"${r2}\";\n",
    "    \n",
    "  mv samples/${sample}/rna/star/${sample}_Aligned.out.sam \\\n",
    "     samples/${sample}/rna/${sample}.star.sam\n",
    "  # Prepare CHAIR-compatible SAMs\n",
    "  grep -v \"^@\" \\\n",
    "    samples/${sample}/rna/${sample}.star.sam | \\\n",
    "    sort -s -k1,1 | \\\n",
    "    awk \"$5 == 255\" | \\\n",
    "    > samples/${sample}/rna/${sample}.name-clean.sam\n",
    "  \n",
    "  # Prepare BAMs for phASER\n",
    "  samtools view -b -@4 samples/${sample}/rna/${sample}.name-clean.sam | \\\n",
    "    samtools sort -@3 -o samples/${sample}/rna/${sample}.name-clean.bam \n",
    "  samtools index samples/${sample}/rna/${sample}.name-clean.bam\n",
    "    \n",
    "  # [optional] rm -r samples/${sample}/rna/star \n",
    "done\n",
    "```\n",
    " \n",
    "A successful run's output should look like:\n",
    "```\n",
    "Nov 21 21:11:05 ..... started STAR run\n",
    "Nov 21 21:11:05 ..... loading genome\n",
    "Nov 21 21:11:30 ..... started 1st pass mapping\n",
    "Nov 21 21:14:43 ..... finished 1st pass mapping\n",
    "Nov 21 21:14:44 ..... inserting junctions into the genome indices\n",
    "Nov 21 21:16:39 ..... started mapping\n",
    "Nov 21 21:20:53 ..... finished successfully\n",
    "Time: 589.14 s\n",
    "Mem:  39716452 Kb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1wlMI7KItgE"
   },
   "source": [
    "## Phasing \n",
    "\n",
    "### Phasing with HapTree-X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rat8aYPHjY7n"
   },
   "source": [
    "#### Chair output preparation\n",
    "\n",
    "```bash\n",
    "for sample in NA12878 NA24143 NA24149 NA24385 NA24631 ; \n",
    "do\n",
    "  mkdir -p samples/${sample}/haptreex\n",
    "  mesa tools/chair-deniz/chair \\\n",
    "    samples/${sample}/giab/${sample}.blind.vcf \\\n",
    "    samples/${sample}/rna/${sample}.name-clean.sam \\\n",
    "    samples/${sample}/haptreex/${sample}-rna.chair \\\n",
    "    1 TRANS_FILTER PCR_DUP_FILTER CONFLICT_FILTER \n",
    "done\n",
    "```\n",
    "\n",
    "A single run takes less than 5 minutes and expected output is something like:\n",
    "```\n",
    "OPT flag: TRANS_FILTER\n",
    "OPT flag: PCR_DUP_FILTER\n",
    "OPT flag: CONFLICT_FILTER\n",
    "numLinesProcessed: 20000000 [...]\n",
    "Time: 160.73 s\n",
    "Mem:  99952 Kb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlfseLvHU58a"
   },
   "source": [
    "#### Run HapTree-X in DASE mode\n",
    "\n",
    "```bash\n",
    "for sample in NA12878 NA24143 NA24149 NA24385 NA24631 ; \n",
    "do\n",
    "  echo -e \"\\n${sample}\";\n",
    "  echo \"=====================================================\";\n",
    "\n",
    "  mesa python2 tools/haptreex-master/HapTree.py \\\n",
    "    --vcf=samples/${sample}/giab/${sample}.blind.vcf \\\n",
    "    --RNAfragmat=samples/${sample}/haptreex/${sample}-rna.chair \\\n",
    "    --gene_info=resources/Homo_sapiens.GRCh37.87.gtf \\\n",
    "    --outputfolder=samples/${sample}/haptreex/rna\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output on empty kraken:\n",
    "```\n",
    "NA12878\n",
    "=====================================================\n",
    "Loading VCF file for scoring\n",
    "Loading and formatting fragments\n",
    "1008715 reads of sufficient quality\n",
    "47358 distinct reads\n",
    "Loading VCF file\n",
    "Preparing data for ReadGraph\n",
    "Loading and formatting genes\n",
    "running through genes\n",
    "graph made\n",
    "assigning rates\n",
    "rates assigned\n",
    "('Pt 1 took ', 46.92121696472168)\n",
    "('stats took ', 0.018706083297729492)\n",
    "Making ReadGraph\n",
    "9876 SNPs in non-trivial connected components\n",
    "('Pt 2 took ', 0.177872896194458)\n",
    "('Pt 3 took ', 0.23997712135314941)\n",
    "('Pt 4 took ', 0.02936100959777832)\n",
    "('Total took ', 47.387134075164795)\n",
    "Time: 50.36 s\n",
    "Mem:  4994404 Kb\n",
    "\n",
    "NA24143\n",
    "=====================================================\n",
    "Loading VCF file for scoring\n",
    "Loading and formatting fragments\n",
    "1117697 reads of sufficient quality\n",
    "38120 distinct reads\n",
    "Loading VCF file\n",
    "Preparing data for ReadGraph\n",
    "Loading and formatting genes\n",
    "running through genes\n",
    "graph made\n",
    "assigning rates\n",
    "rates assigned\n",
    "('Pt 1 took ', 41.883825063705444)\n",
    "('stats took ', 0.01724696159362793)\n",
    "Making ReadGraph\n",
    "7909 SNPs in non-trivial connected components\n",
    "('Pt 2 took ', 0.22679901123046875)\n",
    "('Pt 3 took ', 0.1896979808807373)\n",
    "('Pt 4 took ', 0.0278470516204834)\n",
    "('Total took ', 42.34541606903076)\n",
    "Time: 45.44 s\n",
    "Mem:  4930284 Kb\n",
    "\n",
    "NA24149\n",
    "=====================================================\n",
    "Loading VCF file for scoring\n",
    "Loading and formatting fragments\n",
    "1305232 reads of sufficient quality\n",
    "37270 distinct reads\n",
    "Loading VCF file\n",
    "Preparing data for ReadGraph\n",
    "Loading and formatting genes\n",
    "running through genes\n",
    "graph made\n",
    "assigning rates\n",
    "rates assigned\n",
    "('Pt 1 took ', 42.62701988220215)\n",
    "('stats took ', 0.017560958862304688)\n",
    "Making ReadGraph\n",
    "6994 SNPs in non-trivial connected components\n",
    "('Pt 2 took ', 0.1820070743560791)\n",
    "('Pt 3 took ', 0.16524100303649902)\n",
    "('Pt 4 took ', 0.021738052368164062)\n",
    "('Total took ', 43.013566970825195)\n",
    "Time: 45.67 s\n",
    "Mem:  4916524 Kb\n",
    "\n",
    "NA24385\n",
    "=====================================================\n",
    "Loading VCF file for scoring\n",
    "Loading and formatting fragments\n",
    "945888 reads of sufficient quality\n",
    "65160 distinct reads\n",
    "Loading VCF file\n",
    "Preparing data for ReadGraph\n",
    "Loading and formatting genes\n",
    "running through genes\n",
    "graph made\n",
    "assigning rates\n",
    "rates assigned\n",
    "('Pt 1 took ', 41.47194004058838)\n",
    "('stats took ', 0.020869970321655273)\n",
    "Making ReadGraph\n",
    "13255 SNPs in non-trivial connected components\n",
    "('Pt 2 took ', 0.273906946182251)\n",
    "('Pt 3 took ', 0.3198421001434326)\n",
    "('Pt 4 took ', 0.03827786445617676)\n",
    "('Total took ', 42.124836921691895)\n",
    "Time: 44.75 s\n",
    "Mem:  5002228 Kb\n",
    "\n",
    "NA24631\n",
    "=====================================================\n",
    "Loading VCF file for scoring\n",
    "Loading and formatting fragments\n",
    "1610738 reads of sufficient quality\n",
    "68997 distinct reads\n",
    "Loading VCF file\n",
    "Preparing data for ReadGraph\n",
    "Loading and formatting genes\n",
    "running through genes\n",
    "graph made\n",
    "assigning rates\n",
    "rates assigned\n",
    "('Pt 1 took ', 48.58053517341614)\n",
    "('stats took ', 0.023324012756347656)\n",
    "Making ReadGraph\n",
    "14110 SNPs in non-trivial connected components\n",
    "('Pt 2 took ', 1.5242679119110107)\n",
    "('Pt 3 took ', 0.3374600410461426)\n",
    "('Pt 4 took ', 0.04451608657836914)\n",
    "('Total took ', 50.51010322570801)\n",
    "Time: 53.26 s\n",
    "Mem:  4978432 Kb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running HapCUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "\n",
    "Create HAIRS for HapCUT(2):\n",
    "\n",
    "```bash\n",
    "for sample in NA12878 NA24143 NA24149 NA24385 NA24631 ; \n",
    "do\n",
    "  echo -e \"\\n${sample}\"\n",
    "  echo \"=====================================================\"\n",
    "  mkdir -p samples/${sample}/hapcut\n",
    "  \n",
    "  # RNA: takes ~1m/sample\n",
    "  mesa tools/hapcut2-master/build/extractHAIRS \\\n",
    "    --bam samples/${sample}/rna/${sample}.name-clean.bam  \\\n",
    "    --vcf samples/${sample}/giab/${sample}.blind.vcf \\\n",
    "    --mbq 0 --mmq 0 --maxIS 1000000000 --minIS 0 \\\n",
    "    --out samples/${sample}/hapcut/${sample}-rna.chair\n",
    "    \n",
    "  # WXS: takes ~3m/sample\n",
    "  mesa tools/hapcut2-master/build/extractHAIRS \\\n",
    "    --bam samples/${sample}/giab/${sample}.grch37.wxs.bam  \\\n",
    "    --vcf samples/${sample}/giab/${sample}.blind.vcf \\\n",
    "    --out samples/${sample}/hapcut/${sample}-wxs.chair\n",
    "\n",
    "  # WGS: takes ~hour+/sample\n",
    "  mesa tools/hapcut2-master/build/extractHAIRS \\\n",
    "    --bam samples/${sample}/giab/${sample}.hs37d5.wgs.bam  \\\n",
    "    --vcf samples/${sample}/giab/${sample}.blind.vcf \\\n",
    "    --out samples/${sample}/hapcut/${sample}-wgs.chair\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running phASER\n",
    "\n",
    "phASER is ran as follows:\n",
    "\n",
    "```bash\n",
    "for id sample in 1 NA12878 2 NA24385 3 NA24149 4 NA24143 5 NA24631 ; \n",
    "do\n",
    "  echo -e \"\\n${sample} (HG00${id})\"\n",
    "  echo \"=====================================================\"\n",
    "  mkdir -p samples/${sample}/phaser\n",
    "  \n",
    "  mesa python2 tools/phaser-v1.1.0/phaser/phaser.py \\\n",
    "    --vcf samples/${sample}/giab/${sample}.blind.vcf.gz \\\n",
    "    --bam samples/${sample}/rna/${sample}.name-clean.bam \\\n",
    "    --paired_end 1 --mapq 255 --baseq 0 \\\n",
    "    --sample HG00${id} \\\n",
    "    --o samples/${sample}/phaser/${sample}\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output on empty kraken:\n",
    "```\n",
    "NA12878 (HG001)\n",
    "=====================================================\n",
    "\n",
    "##################################################\n",
    "              Welcome to phASER v1.1.0\n",
    "  Author: Stephane Castel (scastel@nygenome.org)\n",
    "  Updated by: Bishwa K. Giri (bkgiri@uncg.edu)\n",
    "##################################################\n",
    "\n",
    "Completed the check of dependencies and input files availability...\n",
    "\n",
    "STARTED \"Read backed phasing and ASE/haplotype analyses\" ...\n",
    "    DATE, TIME : 2019-01-07, 19:45:06\n",
    "#1. Loading heterozygous variants into intervals...\n",
    "Processing sample named HG001\n",
    "    using all the chromosomes ...\n",
    "    processing VCF...\n",
    "\n",
    "    Memory efficient mode is deactivated...\n",
    "    If RAM is limited, activate memory efficient mode using the flag \"--process_slow = 1\"...\n",
    "\n",
    "     creating variant mapping table...\n",
    "          1968169 heterozygous sites being used for phasing (0 filtered, 0 indels excluded, 1968169 unphased)\n",
    "\n",
    "#2. Retrieving reads that overlap heterozygous sites...\n",
    "     file: samples/NA12878/rna/NA12878.name-clean.bam\n",
    "          minimum mapq: 255\n",
    "          mapping reads to variants...\n",
    "               completed chromosome 1...\n",
    "               completed chromosome 2...\n",
    "               completed chromosome 3...\n",
    "               completed chromosome 4...\n",
    "               completed chromosome 5...\n",
    "               completed chromosome 6...\n",
    "               completed chromosome 7...\n",
    "               completed chromosome 8...\n",
    "               completed chromosome 9...\n",
    "               completed chromosome 10...\n",
    "               completed chromosome 11...\n",
    "               completed chromosome 12...\n",
    "               completed chromosome 13...\n",
    "               completed chromosome 14...\n",
    "               completed chromosome 15...\n",
    "               completed chromosome 16...\n",
    "               completed chromosome 17...\n",
    "               completed chromosome 18...\n",
    "               completed chromosome 19...\n",
    "               completed chromosome 20...\n",
    "               completed chromosome 21...\n",
    "               completed chromosome 22...\n",
    "               completed chromosome X...\n",
    "          processing mapped reads...\n",
    "          using alignment score cutoff of 122\n",
    "          retrieved 1201340 reads\n",
    "#3. Identifying connected variants...\n",
    "     calculating sequencing noise level...\n",
    "     sequencing noise level estimated at 0.000533\n",
    "     creating read sets...\n",
    "     generating read connectivity map...\n",
    "     testing variant connections versus noise...\n",
    "     87 variant connections dropped because of conflicting configurations (threshold = 0.010000)\n",
    "     35232 variants covered by at least 1 read\n",
    "#4. Identifying haplotype blocks...\n",
    "#5. Phasing blocks...\n",
    "#6. Outputting haplotypes...\n",
    "#7. Outputting phased VCF...\n",
    "     GT field is not being updated with phASER genome wide phase. This can be changed using the --gw_phase_vcf argument.\n",
    "     Compressing and tabix indexing output VCF...\n",
    "\n",
    "     COMPLETED using 1201340 reads in 593 seconds using 1 threads\n",
    "     PHASED  9519 of 1968169 all variants (= 0.004836) with at least one other variant\n",
    "     GENOME WIDE PHASED  0 of 1968169 unphased variants (= 0.000000)\n",
    "     GENOME WIDE PHASE CORRECTED  0 of 1968169 variants (= 0.000000)\n",
    "     Global maximum memory usage: 1175.47 (mb)\n",
    "\n",
    "COMPLETED \"Read backed phasing\" of sample HG001 in 00:09:54 hh:mm:ss\n",
    "DATE, TIME : 2019-01-07, 19:55:00\n",
    "\n",
    "The End.\n",
    "Time: 597.79 s\n",
    "Mem:  1203684 Kb\n",
    "\n",
    "NA24385 (HG002)\n",
    "=====================================================\n",
    "\n",
    "##################################################\n",
    "              Welcome to phASER v1.1.0\n",
    "  Author: Stephane Castel (scastel@nygenome.org)\n",
    "  Updated by: Bishwa K. Giri (bkgiri@uncg.edu)\n",
    "##################################################\n",
    "\n",
    "Completed the check of dependencies and input files availability...\n",
    "\n",
    "STARTED \"Read backed phasing and ASE/haplotype analyses\" ...\n",
    "    DATE, TIME : 2019-01-07, 19:55:03\n",
    "#1. Loading heterozygous variants into intervals...\n",
    "Processing sample named HG002\n",
    "    using all the chromosomes ...\n",
    "    processing VCF...\n",
    "\n",
    "    Memory efficient mode is deactivated...\n",
    "    If RAM is limited, activate memory efficient mode using the flag \"--process_slow = 1\"...\n",
    "\n",
    "     creating variant mapping table...\n",
    "          1901907 heterozygous sites being used for phasing (0 filtered, 0 indels excluded, 1901907 unphased)\n",
    "\n",
    "#2. Retrieving reads that overlap heterozygous sites...\n",
    "     file: samples/NA24385/rna/NA24385.name-clean.bam\n",
    "          minimum mapq: 255\n",
    "          mapping reads to variants...\n",
    "               completed chromosome 1...\n",
    "               completed chromosome 2...\n",
    "               completed chromosome 3...\n",
    "               completed chromosome 4...\n",
    "               completed chromosome 5...\n",
    "               completed chromosome 6...\n",
    "               completed chromosome 7...\n",
    "               completed chromosome 8...\n",
    "               completed chromosome 9...\n",
    "               completed chromosome 10...\n",
    "               completed chromosome 11...\n",
    "               completed chromosome 12...\n",
    "               completed chromosome 13...\n",
    "               completed chromosome 14...\n",
    "               completed chromosome 15...\n",
    "               completed chromosome 16...\n",
    "               completed chromosome 17...\n",
    "               completed chromosome 18...\n",
    "               completed chromosome 19...\n",
    "               completed chromosome 20...\n",
    "               completed chromosome 21...\n",
    "               completed chromosome 22...\n",
    "          processing mapped reads...\n",
    "          using alignment score cutoff of 122\n",
    "          retrieved 1070439 reads\n",
    "#3. Identifying connected variants...\n",
    "     calculating sequencing noise level...\n",
    "     sequencing noise level estimated at 0.000491\n",
    "     creating read sets...\n",
    "     generating read connectivity map...\n",
    "     testing variant connections versus noise...\n",
    "     115 variant connections dropped because of conflicting configurations (threshold = 0.010000)\n",
    "     49065 variants covered by at least 1 read\n",
    "#4. Identifying haplotype blocks...\n",
    "#5. Phasing blocks...\n",
    "#6. Outputting haplotypes...\n",
    "#7. Outputting phased VCF...\n",
    "     GT field is not being updated with phASER genome wide phase. This can be changed using the --gw_phase_vcf argument.\n",
    "     Compressing and tabix indexing output VCF...\n",
    "\n",
    "     COMPLETED using 1070439 reads in 626 seconds using 1 threads\n",
    "     PHASED  12789 of 1901907 all variants (= 0.006724) with at least one other variant\n",
    "     GENOME WIDE PHASED  0 of 1901907 unphased variants (= 0.000000)\n",
    "     GENOME WIDE PHASE CORRECTED  0 of 1901907 variants (= 0.000000)\n",
    "     Global maximum memory usage: 1137.36 (mb)\n",
    "\n",
    "COMPLETED \"Read backed phasing\" of sample HG002 in 00:10:27 hh:mm:ss\n",
    "DATE, TIME : 2019-01-07, 20:05:30\n",
    "\n",
    "The End.\n",
    "Time: 629.82 s\n",
    "Mem:  1164660 Kb\n",
    "\n",
    "NA24149 (HG003)\n",
    "=====================================================\n",
    "\n",
    "##################################################\n",
    "              Welcome to phASER v1.1.0\n",
    "  Author: Stephane Castel (scastel@nygenome.org)\n",
    "  Updated by: Bishwa K. Giri (bkgiri@uncg.edu)\n",
    "##################################################\n",
    "\n",
    "Completed the check of dependencies and input files availability...\n",
    "\n",
    "STARTED \"Read backed phasing and ASE/haplotype analyses\" ...\n",
    "    DATE, TIME : 2019-01-07, 20:05:33\n",
    "#1. Loading heterozygous variants into intervals...\n",
    "Processing sample named HG003\n",
    "    using all the chromosomes ...\n",
    "    processing VCF...\n",
    "\n",
    "    Memory efficient mode is deactivated...\n",
    "    If RAM is limited, activate memory efficient mode using the flag \"--process_slow = 1\"...\n",
    "\n",
    "     creating variant mapping table...\n",
    "          1854441 heterozygous sites being used for phasing (0 filtered, 0 indels excluded, 1854441 unphased)\n",
    "\n",
    "#2. Retrieving reads that overlap heterozygous sites...\n",
    "     file: samples/NA24149/rna/NA24149.name-clean.bam\n",
    "          minimum mapq: 255\n",
    "          mapping reads to variants...\n",
    "               completed chromosome 1...\n",
    "               completed chromosome 2...\n",
    "               completed chromosome 3...\n",
    "               completed chromosome 4...\n",
    "               completed chromosome 5...\n",
    "               completed chromosome 6...\n",
    "               completed chromosome 7...\n",
    "               completed chromosome 8...\n",
    "               completed chromosome 9...\n",
    "               completed chromosome 10...\n",
    "               completed chromosome 11...\n",
    "               completed chromosome 12...\n",
    "               completed chromosome 13...\n",
    "               completed chromosome 14...\n",
    "               completed chromosome 15...\n",
    "               completed chromosome 16...\n",
    "               completed chromosome 17...\n",
    "               completed chromosome 18...\n",
    "               completed chromosome 19...\n",
    "               completed chromosome 20...\n",
    "               completed chromosome 21...\n",
    "               completed chromosome 22...\n",
    "          processing mapped reads...\n",
    "          using alignment score cutoff of 116\n",
    "          retrieved 1490547 reads\n",
    "#3. Identifying connected variants...\n",
    "     calculating sequencing noise level...\n",
    "     sequencing noise level estimated at 0.000458\n",
    "     creating read sets...\n",
    "     generating read connectivity map...\n",
    "     testing variant connections versus noise...\n",
    "     256 variant connections dropped because of conflicting configurations (threshold = 0.010000)\n",
    "     28111 variants covered by at least 1 read\n",
    "#4. Identifying haplotype blocks...\n",
    "#5. Phasing blocks...\n",
    "#6. Outputting haplotypes...\n",
    "#7. Outputting phased VCF...\n",
    "     GT field is not being updated with phASER genome wide phase. This can be changed using the --gw_phase_vcf argument.\n",
    "     Compressing and tabix indexing output VCF...\n",
    "\n",
    "     COMPLETED using 1490547 reads in 683 seconds using 1 threads\n",
    "     PHASED  6442 of 1854441 all variants (= 0.003474) with at least one other variant\n",
    "     GENOME WIDE PHASED  0 of 1854441 unphased variants (= 0.000000)\n",
    "     GENOME WIDE PHASE CORRECTED  0 of 1854441 variants (= 0.000000)\n",
    "     Global maximum memory usage: 1149.44 (mb)\n",
    "\n",
    "COMPLETED \"Read backed phasing\" of sample HG003 in 00:11:24 hh:mm:ss\n",
    "DATE, TIME : 2019-01-07, 20:16:57\n",
    "\n",
    "The End.\n",
    "Time: 688.35 s\n",
    "Mem:  1177024 Kb\n",
    "\n",
    "NA24143 (HG004)\n",
    "=====================================================\n",
    "\n",
    "##################################################\n",
    "              Welcome to phASER v1.1.0\n",
    "  Author: Stephane Castel (scastel@nygenome.org)\n",
    "  Updated by: Bishwa K. Giri (bkgiri@uncg.edu)\n",
    "##################################################\n",
    "\n",
    "Completed the check of dependencies and input files availability...\n",
    "\n",
    "STARTED \"Read backed phasing and ASE/haplotype analyses\" ...\n",
    "    DATE, TIME : 2019-01-07, 20:17:01\n",
    "#1. Loading heterozygous variants into intervals...\n",
    "Processing sample named HG004\n",
    "    using all the chromosomes ...\n",
    "    processing VCF...\n",
    "\n",
    "    Memory efficient mode is deactivated...\n",
    "    If RAM is limited, activate memory efficient mode using the flag \"--process_slow = 1\"...\n",
    "\n",
    "     creating variant mapping table...\n",
    "          1890262 heterozygous sites being used for phasing (0 filtered, 0 indels excluded, 1890262 unphased)\n",
    "\n",
    "#2. Retrieving reads that overlap heterozygous sites...\n",
    "     file: samples/NA24143/rna/NA24143.name-clean.bam\n",
    "          minimum mapq: 255\n",
    "          mapping reads to variants...\n",
    "               completed chromosome 1...\n",
    "               completed chromosome 2...\n",
    "               completed chromosome 3...\n",
    "               completed chromosome 4...\n",
    "               completed chromosome 5...\n",
    "               completed chromosome 6...\n",
    "               completed chromosome 7...\n",
    "               completed chromosome 8...\n",
    "               completed chromosome 9...\n",
    "               completed chromosome 10...\n",
    "               completed chromosome 11...\n",
    "               completed chromosome 12...\n",
    "               completed chromosome 13...\n",
    "               completed chromosome 14...\n",
    "               completed chromosome 15...\n",
    "               completed chromosome 16...\n",
    "               completed chromosome 17...\n",
    "               completed chromosome 18...\n",
    "               completed chromosome 19...\n",
    "               completed chromosome 20...\n",
    "               completed chromosome 21...\n",
    "               completed chromosome 22...\n",
    "          processing mapped reads...\n",
    "          using alignment score cutoff of 126\n",
    "          retrieved 1187348 reads\n",
    "#3. Identifying connected variants...\n",
    "     calculating sequencing noise level...\n",
    "     sequencing noise level estimated at 0.000529\n",
    "     creating read sets...\n",
    "     generating read connectivity map...\n",
    "     testing variant connections versus noise...\n",
    "     285 variant connections dropped because of conflicting configurations (threshold = 0.010000)\n",
    "     28443 variants covered by at least 1 read\n",
    "#4. Identifying haplotype blocks...\n",
    "#5. Phasing blocks...\n",
    "#6. Outputting haplotypes...\n",
    "#7. Outputting phased VCF...\n",
    "     GT field is not being updated with phASER genome wide phase. This can be changed using the --gw_phase_vcf argument.\n",
    "     Compressing and tabix indexing output VCF...\n",
    "\n",
    "     COMPLETED using 1187348 reads in 839 seconds using 1 threads\n",
    "     PHASED  7194 of 1890262 all variants (= 0.003806) with at least one other variant\n",
    "     GENOME WIDE PHASED  0 of 1890262 unphased variants (= 0.000000)\n",
    "     GENOME WIDE PHASE CORRECTED  0 of 1890262 variants (= 0.000000)\n",
    "     Global maximum memory usage: 1129.78 (mb)\n",
    "\n",
    "COMPLETED \"Read backed phasing\" of sample HG004 in 00:13:59 hh:mm:ss\n",
    "DATE, TIME : 2019-01-07, 20:31:01\n",
    "\n",
    "The End.\n",
    "Time: 842.48 s\n",
    "Mem:  1156896 Kb\n",
    "\n",
    "NA24631 (HG005)\n",
    "=====================================================\n",
    "\n",
    "##################################################\n",
    "              Welcome to phASER v1.1.0\n",
    "  Author: Stephane Castel (scastel@nygenome.org)\n",
    "  Updated by: Bishwa K. Giri (bkgiri@uncg.edu)\n",
    "##################################################\n",
    "\n",
    "Completed the check of dependencies and input files availability...\n",
    "\n",
    "STARTED \"Read backed phasing and ASE/haplotype analyses\" ...\n",
    "    DATE, TIME : 2019-01-07, 20:31:04\n",
    "#1. Loading heterozygous variants into intervals...\n",
    "Processing sample named HG005\n",
    "    using all the chromosomes ...\n",
    "    processing VCF...\n",
    "\n",
    "    Memory efficient mode is deactivated...\n",
    "    If RAM is limited, activate memory efficient mode using the flag \"--process_slow = 1\"...\n",
    "\n",
    "     creating variant mapping table...\n",
    "          1809385 heterozygous sites being used for phasing (0 filtered, 0 indels excluded, 1809385 unphased)\n",
    "\n",
    "#2. Retrieving reads that overlap heterozygous sites...\n",
    "     file: samples/NA24631/rna/NA24631.name-clean.bam\n",
    "          minimum mapq: 255\n",
    "          mapping reads to variants...\n",
    "               completed chromosome 1...\n",
    "               completed chromosome 2...\n",
    "               completed chromosome 3...\n",
    "               completed chromosome 4...\n",
    "               completed chromosome 5...\n",
    "               completed chromosome 6...\n",
    "               completed chromosome 7...\n",
    "               completed chromosome 8...\n",
    "               completed chromosome 9...\n",
    "               completed chromosome 10...\n",
    "               completed chromosome 11...\n",
    "               completed chromosome 12...\n",
    "               completed chromosome 13...\n",
    "               completed chromosome 14...\n",
    "               completed chromosome 15...\n",
    "               completed chromosome 16...\n",
    "               completed chromosome 17...\n",
    "               completed chromosome 18...\n",
    "               completed chromosome 19...\n",
    "               completed chromosome 20...\n",
    "               completed chromosome 21...\n",
    "               completed chromosome 22...\n",
    "          processing mapped reads...\n",
    "          using alignment score cutoff of 123\n",
    "          retrieved 1720342 reads\n",
    "#3. Identifying connected variants...\n",
    "     calculating sequencing noise level...\n",
    "     sequencing noise level estimated at 0.000571\n",
    "     creating read sets...\n",
    "     generating read connectivity map...\n",
    "     testing variant connections versus noise...\n",
    "     43 variant connections dropped because of conflicting configurations (threshold = 0.010000)\n",
    "     51763 variants covered by at least 1 read\n",
    "#4. Identifying haplotype blocks...\n",
    "#5. Phasing blocks...\n",
    "#6. Outputting haplotypes...\n",
    "#7. Outputting phased VCF...\n",
    "     GT field is not being updated with phASER genome wide phase. This can be changed using the --gw_phase_vcf argument.\n",
    "     Compressing and tabix indexing output VCF...\n",
    "\n",
    "     COMPLETED using 1720342 reads in 980 seconds using 1 threads\n",
    "     PHASED  13617 of 1809385 all variants (= 0.007526) with at least one other variant\n",
    "     GENOME WIDE PHASED  0 of 1809385 unphased variants (= 0.000000)\n",
    "     GENOME WIDE PHASE CORRECTED  0 of 1809385 variants (= 0.000000)\n",
    "     Global maximum memory usage: 1556.89 (mb)\n",
    "\n",
    "COMPLETED \"Read backed phasing\" of sample HG005 in 00:16:20 hh:mm:ss\n",
    "DATE, TIME : 2019-01-07, 20:47:24\n",
    "\n",
    "The End.\n",
    "Time: 983.30 s\n",
    "Mem:  1594252 Kb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wNpEfwJI816"
   },
   "source": [
    "# TODO <_below_> :\n",
    "### Testing the results with `error_rates.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPxUDmspJIzi"
   },
   "outputs": [],
   "source": [
    "```bash\n",
    "python ./githubX/error_rates.py /scratch1/haptreex_rnaseq/STAR-2.6.1d/giab_vcf/GM12878.vcf ./Hap_Runs/haptreex_GM12878/HapTreeX_withDASE_output.txt```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9t1Cd_Z5JOFz"
   },
   "source": [
    "For GM12878, giab reference:\n",
    "\n",
    "```\n",
    "tool:            None\n",
    "dataset:         HapTreeX_withDASE_output.txt\n",
    "switch rate:     0\n",
    "mismatch rate:   0\n",
    "flat rate:       0\n",
    "missing rate:    0\n",
    "switch errors:   12\n",
    "poss. switch:    549\n",
    "mismatch errors: 128\n",
    "poss. mismatch:  9857\n",
    "flat errors:     149\n",
    "poss. flat:      9857\n",
    "phased count:    9896\n",
    "num covered:     0\n",
    "AN50:            0\n",
    "N50:             0\n",
    "max blk snp %:   0\n",
    "runtime:         -1\n",
    "missed vcf:      0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmOXzG2KJe8e"
   },
   "source": [
    "For GM24143,  giab ref:\n",
    "\n",
    "```\n",
    "tool:            None\n",
    "dataset:         HapTreeX_withDASE_output.txt\n",
    "switch rate:     0\n",
    "mismatch rate:   0\n",
    "flat rate:       0\n",
    "missing rate:    0\n",
    "switch errors:   4\n",
    "poss. switch:    62\n",
    "mismatch errors: 36\n",
    "poss. mismatch:  1926\n",
    "flat errors:     36\n",
    "poss. flat:      1926\n",
    "phased count:    7922\n",
    "num covered:     0\n",
    "AN50:            0\n",
    "N50:             0\n",
    "max blk snp %:   0\n",
    "runtime:         -1\n",
    "missed vcf:      0\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzK1-EviKOzh"
   },
   "source": [
    "For GM24149, giab reference:\n",
    "\n",
    "tool:            None\n",
    "dataset:         HapTreeX_withDASE_output.txt\n",
    "switch rate:     0\n",
    "mismatch rate:   0\n",
    "flat rate:       0\n",
    "missing rate:    0\n",
    "switch errors:   2\n",
    "poss. switch:    60\n",
    "mismatch errors: 53\n",
    "poss. mismatch:  1979\n",
    "flat errors:     48\n",
    "poss. flat:      1979\n",
    "phased count:    7003\n",
    "num covered:     0\n",
    "AN50:            0\n",
    "N50:             0\n",
    "max blk snp %:   0\n",
    "runtime:         -1\n",
    "missed vcf:      0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "erK6A790Kk6c"
   },
   "source": [
    "For GM24386, giab reference:\n",
    "\n",
    "tool:            None\n",
    "dataset:         HapTreeX_withDASE_output.txt\n",
    "switch rate:     0\n",
    "mismatch rate:   0\n",
    "flat rate:       0\n",
    "missing rate:    0\n",
    "switch errors:   7\n",
    "poss. switch:    648\n",
    "mismatch errors: 198\n",
    "poss. mismatch:  11169\n",
    "flat errors:     205\n",
    "poss. flat:      11169\n",
    "phased count:    13271\n",
    "num covered:     0\n",
    "AN50:            0\n",
    "N50:             0\n",
    "max blk snp %:   0\n",
    "runtime:         -1\n",
    "missed vcf:      0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhMbxvxbKtuN"
   },
   "source": [
    "For GM24631, giab reference:\n",
    "\n",
    "tool:            None\n",
    "dataset:         HapTreeX_withDASE_output.txt\n",
    "switch rate:     0\n",
    "mismatch rate:   0\n",
    "flat rate:       0\n",
    "missing rate:    0\n",
    "switch errors:   3\n",
    "poss. switch:    96\n",
    "mismatch errors: 44\n",
    "poss. mismatch:  3329\n",
    "flat errors:     42\n",
    "poss. flat:      3329\n",
    "phased count:    14127\n",
    "num covered:     0\n",
    "AN50:            0\n",
    "N50:             0\n",
    "max blk snp %:   0\n",
    "runtime:         -1\n",
    "missed vcf:      0\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HapTree-X.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
